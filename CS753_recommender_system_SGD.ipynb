{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f7c828",
   "metadata": {},
   "source": [
    "<h1> CS753 Assignment 4 Recommender Systems</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb169dad",
   "metadata": {},
   "source": [
    "<h4>1. Reading json files: https://www.geeksforgeeks.org/read-json-file-using-python/ </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c05c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d27952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open(r\"C:\\Users\\ylive\\OneDrive\\Documents\\compsci753\\homework\\train.json\") as f:\n",
    "    train_data = [json.loads(s) for s in f.readlines()]\n",
    "\n",
    "with open(r\"C:\\Users\\ylive\\OneDrive\\Documents\\compsci753\\homework\\val.json\") as f:\n",
    "    val_data = [json.loads(s) for s in f.readlines()]\n",
    "\n",
    "with open(r\"C:\\Users\\ylive\\OneDrive\\Documents\\compsci753\\homework\\test.json\") as f:\n",
    "    test_data = [json.loads(s) for s in f.readlines()]\n",
    "\n",
    "all_data = train_data + val_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88a6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode user and item\n",
    "def encode_user_item(l:list):\n",
    "    user_encode, item_encode = {}, {}\n",
    "    i, j = 0, 0\n",
    "    for r in l:\n",
    "        if r['user_id'] not in user_encode:\n",
    "            user_encode[r['user_id']] = i\n",
    "            i += 1\n",
    "        if r['business_id'] not in item_encode:\n",
    "            item_encode[r['business_id']] = j\n",
    "            j += 1\n",
    "    return user_encode, item_encode\n",
    "\n",
    "user_encode, item_encode = encode_user_item(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8b9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get global bias\n",
    "stars_tot = 0\n",
    "for r in train_data:\n",
    "    stars_tot += r['stars']\n",
    "bg = stars_tot / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bde08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bias for users and items\n",
    "def get_bias(l:list, bg:int):\n",
    "    user_bias, item_bias = {}, {}\n",
    "    for r in l:\n",
    "        if r['user_id'] not in user_bias:\n",
    "            user_bias[r['user_id']] = [r['stars'], 1]\n",
    "        else:\n",
    "            user_bias[r['user_id']][0] += r['stars']\n",
    "            user_bias[r['user_id']][1] += 1\n",
    "\n",
    "        if r['business_id'] not in item_bias:\n",
    "            item_bias[r['business_id']] = [r['stars'], 1]\n",
    "        else:\n",
    "            item_bias[r['business_id']][0] += r['stars']\n",
    "            item_bias[r['business_id']][1] += 1\n",
    "    \n",
    "    for u in user_bias.keys():\n",
    "        user_bias[u] = user_bias[u][0]/user_bias[u][1] - bg\n",
    "\n",
    "    for i in item_bias.keys():\n",
    "        item_bias[i] = item_bias[i][0]/item_bias[i][1] - bg\n",
    "\n",
    "    return user_bias, item_bias\n",
    "\n",
    "user_bias, item_bias = get_bias(train_data, bg)\n",
    "\n",
    "# if an user/item do not appear in training data, set the bias to 0\n",
    "for r in all_data:\n",
    "    if r['user_id'] not in user_bias:\n",
    "        user_bias[r['user_id']] = 0\n",
    "    if r['business_id'] not in item_bias:\n",
    "        item_bias[r['business_id']] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2921510",
   "metadata": {},
   "source": [
    "<h4>1. Task 1: Estimate the global bias bg, user specific bias b(user)i and item specific bias b(item)j on the training data. Report the global bg, the user specific bias of the user with user id= “b4aIMeXOx4cn3bjtdIOo6Q” , item specific bias of the business with business id = “7VQYoXk3Tc8EZeKuXeixeg”. [10 pts] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ac2a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global bias: 3.8290028774583242\n",
      "specific user bias, -0.4605818248267455\n",
      "specific item bias, -0.05122509968054656\n"
     ]
    }
   ],
   "source": [
    "print(f'global bias: {bg}')\n",
    "print(f'specific user bias, {user_bias[\"b4aIMeXOx4cn3bjtdIOo6Q\"]}')\n",
    "print(f'specific item bias, {item_bias[\"7VQYoXk3Tc8EZeKuXeixeg\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1c130",
   "metadata": {},
   "source": [
    "<h4>2. Task 2: Implement the basic latent factor model without considering the bias: rij =qTi dot pj. Set the number of latent factors k = 8. Run Stochastic Gradient Descent (SGD) for 10 epoches with a fixed learning rate η = 0.01 and regularization hyperparameter λ1 = λ2 = 0.3. Report the RMSE on the training data for each epoch. [30 pts]</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47799ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFM(l: list, k: int, seed=753):\n",
    "    lr1, lr2 = .3, .3                                                               # regularization hyperparameter\n",
    "    eta = .01                                                                       # learning rate                 \n",
    "    max_epoch = 10                                                                  # number of epochs\n",
    "\n",
    "    np.random.seed(seed)                                                            # user and item latent\n",
    "    Q = np.random.randn(len(user_encode), k)\n",
    "    P = np.random.randn(len(item_encode), k)\n",
    "\n",
    "    print(f'K = {k}')\n",
    "    \n",
    "    for epoch in range(max_epoch):                                                  # for each epoch\n",
    "        RSS = 0                                                                     # sum of squared residual\n",
    "        for r in l:\n",
    "            uid, iid = user_encode[r['user_id']], item_encode[r['business_id']]     # user and item id\n",
    "            star = r['stars']                                                       # true rating\n",
    "            starhat = Q[uid, :].dot(P[iid, :])                                      # estimated rating\n",
    "            diff = star - starhat\n",
    "\n",
    "            for f in range(k):                                                      # for each latent factor\n",
    "                gu = -2 * diff * P[iid, f] + 2 * lr1 * Q[uid, f]                    # gradient of user\n",
    "                gi = -2 * diff * Q[uid, f] + 2 * lr2 * P[iid, f]                    # gradient of item\n",
    "                Q[uid, f] -= eta * gu                                               # update latent value\n",
    "                P[iid, f] -= eta * gi\n",
    "            RSS += diff**2\n",
    "\n",
    "        print(f'epoch: {epoch}\\tRMSE: {np.sqrt(RSS / len(l))}')\n",
    "    return Q, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b2f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 8\n",
      "epoch: 0\tRMSE: 3.3673747415210062\n",
      "epoch: 1\tRMSE: 1.6285505300063614\n",
      "epoch: 2\tRMSE: 1.2506534989921805\n",
      "epoch: 3\tRMSE: 1.1769729351730478\n",
      "epoch: 4\tRMSE: 1.1527096548402738\n",
      "epoch: 5\tRMSE: 1.1412240509945955\n",
      "epoch: 6\tRMSE: 1.1346082733364387\n",
      "epoch: 7\tRMSE: 1.130342583792446\n",
      "epoch: 8\tRMSE: 1.1273815666579499\n",
      "epoch: 9\tRMSE: 1.1252107693489868\n"
     ]
    }
   ],
   "source": [
    "# train latent factor model\n",
    "_,_ = LFM(train_data, k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351591f9",
   "metadata": {},
   "source": [
    "<h4> 3. Task 3: Use SGD to train the latent factor model with different values of k in {4, 8, 16} and stop after 10 epoches. Report the RMSE for each value of k on the validation data (“val.json”). Pick the model that results in the best RMSE on the validation set and report its RMSE on the test data (“test.json”). [15 pts] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc1a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(l: list, Q, P):\n",
    "    RSS = 0                                                                         # sum of squared residual\n",
    "    for r in l:\n",
    "        uid, iid = user_encode[r['user_id']], item_encode[r['business_id']]         # user and item id\n",
    "        star = r['stars']                                                           # true rating\n",
    "        starhat = Q[uid, :].dot(P[iid, :])                                          # estimated rating\n",
    "        RSS += (star-starhat)**2\n",
    "    return np.sqrt(RSS / len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b5f4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4\n",
      "epoch: 0\tRMSE: 3.2637850071345142\n",
      "epoch: 1\tRMSE: 1.6327983434261724\n",
      "epoch: 2\tRMSE: 1.253585355593168\n",
      "epoch: 3\tRMSE: 1.1857554853469283\n",
      "epoch: 4\tRMSE: 1.1655750540253302\n",
      "epoch: 5\tRMSE: 1.156592278359854\n",
      "epoch: 6\tRMSE: 1.1515745454527673\n",
      "epoch: 7\tRMSE: 1.1483821723447674\n",
      "epoch: 8\tRMSE: 1.1461709154332125\n",
      "epoch: 9\tRMSE: 1.144538340212954\n",
      "K = 8\n",
      "epoch: 0\tRMSE: 3.3673747415210062\n",
      "epoch: 1\tRMSE: 1.6285505300063614\n",
      "epoch: 2\tRMSE: 1.2506534989921805\n",
      "epoch: 3\tRMSE: 1.1769729351730478\n",
      "epoch: 4\tRMSE: 1.1527096548402738\n",
      "epoch: 5\tRMSE: 1.1412240509945955\n",
      "epoch: 6\tRMSE: 1.1346082733364387\n",
      "epoch: 7\tRMSE: 1.130342583792446\n",
      "epoch: 8\tRMSE: 1.1273815666579499\n",
      "epoch: 9\tRMSE: 1.1252107693489868\n",
      "K = 16\n",
      "epoch: 0\tRMSE: 3.5932500658968882\n",
      "epoch: 1\tRMSE: 1.6072781800169862\n",
      "epoch: 2\tRMSE: 1.2365328440116115\n",
      "epoch: 3\tRMSE: 1.1567503363128915\n",
      "epoch: 4\tRMSE: 1.1276708777824709\n",
      "epoch: 5\tRMSE: 1.1133400350125353\n",
      "epoch: 6\tRMSE: 1.1051162545849804\n",
      "epoch: 7\tRMSE: 1.099991918145948\n",
      "epoch: 8\tRMSE: 1.0966420518949864\n",
      "epoch: 9\tRMSE: 1.094387431821155\n"
     ]
    }
   ],
   "source": [
    "# get latent for different number of factors (k)\n",
    "latents = [LFM(train_data, k) for k in (4, 8, 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7256e98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [1.68821657 1.71790704 1.79128982]\n",
      "The RMSE of the best LFM (without bias) on the test set: 1.7585057085341587\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE on the validation set\n",
    "rmse = np.array([evaluate(val_data, *l) for l in latents])\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# get the LFM (without bias) with the best k on validation set\n",
    "best_model = latents[np.argmin(rmse)]\n",
    "\n",
    "# evaluate on the test set\n",
    "print(f'The RMSE of the best LFM (without bias) on the test set: {evaluate(test_data, *best_model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e3907",
   "metadata": {},
   "source": [
    "The RMSEs on the validation set are 1.69 1.72 1.79 when k is 4, 8, and 16, respectively. The best model on the validation set has k=4, and the RMSE on the test set is 1.76."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97504841",
   "metadata": {},
   "source": [
    "<h4> 4. Task 4: Incorporate the bias terms bg, b(user)i and b(item)jto the latent factor model:rij = bg + b(user)i + b(item)j + qTipj and learn the user bias and business bias from data.Initialize the user bias b(user)i and item bias terms b(item)j using the values computed in Task 1. Set the number of latent factors k = 8. Run SGD for 10 epoches with a fixed learning rate η = 0.01 and regularization hyperparameter λ1 = λ2 = λ3 = λ4 = 0.3.Report the RMSE on the training data for each epoch and the learned bias terms.[30 pts]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "590697df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFM_bias(l: list, k: int, bg, user_bias, item_bias, seed=753):\n",
    "    lr1, lr2, lr3, lr4 = .3, .3, .3, .3                                             # regularization hyperparameter\n",
    "    eta = .01                                                                       # learning rate                 \n",
    "    max_epoch = 10                                                                  # number of epochs\n",
    "\n",
    "    user_bias = user_bias.copy()                                                    # leave the original bias unchanged\n",
    "    item_bias = item_bias.copy()\n",
    "\n",
    "    np.random.seed(seed)                                                            # user and item latent\n",
    "    Q = np.random.randn(len(user_encode), k)\n",
    "    P = np.random.randn(len(item_encode), k)\n",
    "\n",
    "    print(f'K = {k}')\n",
    "\n",
    "    for epoch in range(max_epoch):                                                  # for each epoch\n",
    "        RSS = 0                                                                     # sum of squared residual\n",
    "        for r in l:\n",
    "            uid, iid = user_encode[r['user_id']], item_encode[r['business_id']]     # user and item id\n",
    "            star = r['stars']                                                       # true rating\n",
    "            starhat = bg + user_bias[r['user_id']] + \\\n",
    "                item_bias[r['business_id']] + Q[uid, :].dot(P[iid, :])              # estimated rating\n",
    "            diff = star - starhat\n",
    "\n",
    "            for f in range(k):                                                      # for each latent factor\n",
    "                gu = -2 * diff * P[iid, f] + 2 * lr1 * Q[uid, f]                    # gradient of user\n",
    "                gi = -2 * diff * Q[uid, f] + 2 * lr2 * P[iid, f]                    # gradient of item\n",
    "                Q[uid, f] -= eta * gu                                               # update latent value\n",
    "                P[iid, f] -= eta * gi\n",
    "            user_bias[r['user_id']] -= eta * \\\n",
    "                (-2 * diff + 2 * lr3 * user_bias[r['user_id']])                     # update bias\n",
    "            item_bias[r['business_id']] -= eta * \\\n",
    "                (-2 * diff + 2 * lr4 * item_bias[r['business_id']])\n",
    "            RSS += diff**2\n",
    "\n",
    "        print(f'epoch: {epoch}\\tRMSE: {np.sqrt(RSS / len(l))}')\n",
    "    return Q, P, user_bias, item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d278be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 8\n",
      "epoch: 0\tRMSE: 1.5450943564667388\n",
      "epoch: 1\tRMSE: 1.1150599510290227\n",
      "epoch: 2\tRMSE: 1.0830770302123058\n",
      "epoch: 3\tRMSE: 1.0722505259961503\n",
      "epoch: 4\tRMSE: 1.0669333182315974\n",
      "epoch: 5\tRMSE: 1.063781408998576\n",
      "epoch: 6\tRMSE: 1.061699570666377\n",
      "epoch: 7\tRMSE: 1.060226776852334\n",
      "epoch: 8\tRMSE: 1.0591330653409852\n",
      "epoch: 9\tRMSE: 1.0582889577926036\n"
     ]
    }
   ],
   "source": [
    "Q8, P8, bu8, bi8 = LFM_bias(train_data, 8, bg, user_bias, item_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef94738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user specific bias: -0.2556560383594884\n",
      "item specific bias: 0.04003793814146499\n"
     ]
    }
   ],
   "source": [
    "# learned user-specific bias\n",
    "print(f'user specific bias: {bu8[\"b4aIMeXOx4cn3bjtdIOo6Q\"]}')\n",
    "\n",
    "# learned item-specific bias\n",
    "print(f'item specific bias: {bi8[\"7VQYoXk3Tc8EZeKuXeixeg\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52325d5",
   "metadata": {},
   "source": [
    "<h4> 5. Task 5: Similar to Task 3, find the best k on the validation set and apply the corresponding model to the test data. Compare the resulting test RMSE with Task3. [15 pts] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54f3b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bias(l: list, bg, Q, P, bu, bi):\n",
    "    RSS = 0                                                                         # sum of squared residual\n",
    "    for r in l:\n",
    "        uid, iid = user_encode[r['user_id']], item_encode[r['business_id']]         # user and item id\n",
    "        star = r['stars']                                                           # true rating\n",
    "        starhat = bg + user_bias[r['user_id']] + \\\n",
    "            item_bias[r['business_id']] + Q[uid, :].dot(P[iid, :])                  # estimated rating\n",
    "        RSS += (star-starhat)**2\n",
    "    return np.sqrt(RSS / len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8670d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4\n",
      "epoch: 0\tRMSE: 1.328367529467907\n",
      "epoch: 1\tRMSE: 1.1060855737583513\n",
      "epoch: 2\tRMSE: 1.088416228321949\n",
      "epoch: 3\tRMSE: 1.0823947299833754\n",
      "epoch: 4\tRMSE: 1.0793913193537505\n",
      "epoch: 5\tRMSE: 1.0775585785033288\n",
      "epoch: 6\tRMSE: 1.0762954207687971\n",
      "epoch: 7\tRMSE: 1.0753508621566465\n",
      "epoch: 8\tRMSE: 1.0746007339819574\n",
      "epoch: 9\tRMSE: 1.0739756802676534\n",
      "K = 8\n",
      "epoch: 0\tRMSE: 1.5450943564667388\n",
      "epoch: 1\tRMSE: 1.1150599510290227\n",
      "epoch: 2\tRMSE: 1.0830770302123058\n",
      "epoch: 3\tRMSE: 1.0722505259961503\n",
      "epoch: 4\tRMSE: 1.0669333182315974\n",
      "epoch: 5\tRMSE: 1.063781408998576\n",
      "epoch: 6\tRMSE: 1.061699570666377\n",
      "epoch: 7\tRMSE: 1.060226776852334\n",
      "epoch: 8\tRMSE: 1.0591330653409852\n",
      "epoch: 9\tRMSE: 1.0582889577926036\n",
      "K = 16\n",
      "epoch: 0\tRMSE: 1.9175274071555117\n",
      "epoch: 1\tRMSE: 1.1175162513150756\n",
      "epoch: 2\tRMSE: 1.0673835634072868\n",
      "epoch: 3\tRMSE: 1.0506052768372156\n",
      "epoch: 4\tRMSE: 1.0425802317735986\n",
      "epoch: 5\tRMSE: 1.0380734065725827\n",
      "epoch: 6\tRMSE: 1.0353444249287116\n",
      "epoch: 7\tRMSE: 1.0336433988732867\n",
      "epoch: 8\tRMSE: 1.0325867857937394\n",
      "epoch: 9\tRMSE: 1.0319539219244964\n"
     ]
    }
   ],
   "source": [
    "# get different LFM with respect to different k\n",
    "latents_bias = [LFM_bias(train_data, k, bg, user_bias, item_bias) for k in (4, 8, 16)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a5aac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2972461350179727"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bias(val_data, bg, Q8, P8, bu8, bi8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26dfb0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [1.28254049 1.29724614 1.32627313]\n",
      "The RMSE of the best LFM (with bias) on the test set: 1.2749177150868805\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE on the validation set\n",
    "rmse_bias = np.array([evaluate_bias(val_data, bg, *l) for l in latents_bias])\n",
    "print(f'RMSE: {rmse_bias}')\n",
    "\n",
    "# get the LFM (with bias) with the best k on validation set\n",
    "best_model_bias = latents_bias[rmse_bias.argmin()]\n",
    "\n",
    "# evaluate on the test set\n",
    "print(f'The RMSE of the best LFM (with bias) on the test set: {evaluate_bias(test_data, bg, *best_model_bias)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec31661",
   "metadata": {},
   "source": [
    "The RMSEs on the validation set are 1.28, 1.30 1.33 when k is 4, 8, and 16, respectively. The best model on the validation set has k=4, and the RMSE on the test set is 1.27.\n",
    "\n",
    "Compare the resulting RMSE with Task 3, the RMSE decreases from 1.76 to 1.27 (on the test set)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
